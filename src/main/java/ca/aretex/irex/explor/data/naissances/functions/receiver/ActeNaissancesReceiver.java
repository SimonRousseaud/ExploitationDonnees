package ca.aretex.irex.explor.data.naissances.functions.receiver;

import ca.aretex.irex.explor.data.naissances.beans.ActeNaissances;
import ca.aretex.irex.explor.data.naissances.functions.parser.TextToActeNaissancesFunc;
import ca.aretex.irex.explor.data.naissances.types.ActeNaissancesFileInputFormat;
import ca.aretex.irex.explor.data.naissances.types.ActeNaissancesLongWritable;
import ca.aretex.irex.explor.data.naissances.types.ActeNaissancesText;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.apache.hadoop.fs.Path;
import org.apache.spark.api.java.function.Function;
import org.apache.spark.streaming.api.java.JavaDStream;
import org.apache.spark.streaming.api.java.JavaPairInputDStream;
import org.apache.spark.streaming.api.java.JavaStreamingContext;

import java.util.function.Supplier;

@Slf4j
@RequiredArgsConstructor
public class ActeNaissancesReceiver implements Supplier<JavaDStream<ActeNaissances>> {
    private final JavaStreamingContext javaStreamingContext;
    private final String inputPathStr;

    private final TextToActeNaissancesFunc textToActenaissancesFunc = new TextToActeNaissancesFunc();
    private final Function<String, ActeNaissances> mapper = textToActenaissancesFunc::apply;
    private final Function<Path, Boolean> filter = p -> p.getName().endsWith(".txt");

    @Override
    public JavaDStream<ActeNaissances> get() {
        JavaPairInputDStream<ActeNaissancesLongWritable, ActeNaissancesText> inputDStream = javaStreamingContext
                .fileStream(
                        inputPathStr,
                        ActeNaissancesLongWritable.class,
                        ActeNaissancesText.class,
                        ActeNaissancesFileInputFormat.class,
                        filter,
                        true
                );
        return inputDStream.map(t -> t._2().toString()).map(mapper);
    }
}
