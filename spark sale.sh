#!/bin/bash

# Set environment variables
if ! grep -q "SPARK_HOME" /home/ubuntu/.bashrc; then
    echo "export SPARK_HOME=/usr/local/spark" >> /home/ubuntu/.bashrc
    source /home/ubuntu/.bashrc;

fi

if ! grep -q "PATH.*SPARK_HOME" /home/ubuntu/.bashrc; then
    echo "export PATH=\$PATH:\$SPARK_HOME/bin" >> /home/ubuntu/.bashrc
fi

if ! grep -q "USER_PATH_CUSTOM" /home/ubuntu/.bashrc; then
    echo "export USER_PATH_CUSTOM=/home/ubuntu" >> /home/ubuntu/.bashrc
fi

if ! grep -q "HADOOP_HOME" /home/ubuntu/.bashrc; then
    echo "export HADOOP_HOME=/home/ubuntu/hadoop-3.3.4" >> /home/ubuntu/.bashrc
    source /home/ubuntu/.bashrc;
    echo "export HADOOP_INSTALL=/home/ubuntu/hadoop-3.3.4" >> /home/ubuntu/.bashrc
    echo "export HADOOP_MAPRED_HOME=/home/ubuntu/hadoop-3.3.4" >> /home/ubuntu/.bashrc
    echo "export HADOOP_COMMON_HOME=/home/ubuntu/hadoop-3.3.4" >> /home/ubuntu/.bashrc
    echo "export HADOOP_HDFS_HOME=/home/ubuntu/hadoop-3.3.4" >> /home/ubuntu/.bashrc
    echo "export YARN_HOME=/home/ubuntu/hadoop-3.3.4" >> /home/ubuntu/.bashrc
    echo "export HADOOP_COMMON_LIB_NATIVE_DIR=/home/ubuntu/hadoop-3.3.4/lib/native" >> /home/ubuntu/.bashrc
    echo "export PATH=\$PATH:/home/ubuntu/hadoop-3.3.4/sbin:/home/ubuntu/hadoop-3.3.4/bin" >> /home/ubuntu/.bashrc
    echo "export HADOOP_OPTS=/home/ubuntu/hadoop-3.3.4/lib/native" >> /home/ubuntu/.bashrc
fi
source /home/ubuntu/.bashrc;

# Set environment variables
if ! grep -q "SPARK_HOME" ~/.bashrc; then
    echo "export SPARK_HOME=/usr/local/spark" >> ~/.bashrc
    source ~/.bashrc;

fi

if ! grep -q "PATH.*SPARK_HOME" ~/.bashrc; then
    echo "export PATH=\$PATH:\$SPARK_HOME/bin" >> ~/.bashrc
fi

if ! grep -q "USER_PATH_CUSTOM" ~/.bashrc; then
    echo "export USER_PATH_CUSTOM=/home/ubuntu" >> ~/.bashrc
fi

if ! grep -q "HADOOP_HOME" ~/.bashrc; then
    echo "export HADOOP_HOME=/home/ubuntu/hadoop-3.3.4" >> ~/.bashrc
    source ~/.bashrc;
    echo "export HADOOP_INSTALL=/home/ubuntu/hadoop-3.3.4" >> ~/.bashrc
    echo "export HADOOP_MAPRED_HOME=/home/ubuntu/hadoop-3.3.4" >> ~/.bashrc
    echo "export HADOOP_COMMON_HOME=/home/ubuntu/hadoop-3.3.4" >> ~/.bashrc
    echo "export HADOOP_HDFS_HOME=/home/ubuntu/hadoop-3.3.4" >> ~/.bashrc
    echo "export YARN_HOME=/home/ubuntu/hadoop-3.3.4" >> ~/.bashrc
    echo "export HADOOP_COMMON_LIB_NATIVE_DIR=/home/ubuntu/hadoop-3.3.4/lib/native" >> ~/.bashrc
    echo "export PATH=\$PATH:/home/ubuntu/hadoop-3.3.4/sbin:/home/ubuntu/hadoop-3.3.4/bin" >> ~/.bashrc
    echo "export HADOOP_OPTS=/home/ubuntu/hadoop-3.3.4/lib/native" >> ~/.bashrc
fi
source ~/.bashrc;

# Update package manager
sudo apt update -y
echo "APT update OK "

# Install Java
sudo apt install openjdk-11-jdk git maven -y
echo "APT install OK "

# Install Hadoop

# wget -P "/home/ubuntu" https://dlcdn.apache.org/hadoop/common/hadoop-3.3.4/hadoop-3.3.4.tar.gz
cd /home/ubuntu && tar -xvzf hadoop-3.3.4.tar.gz
cd hadoop-3.3.4/

echo "export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64" >> /home/ubuntu/hadoop-3.3.4/etc/hadoop/hadoop-env.sh;
source /home/ubuntu/hadoop-3.3.4/etc/hadoop/hadoop-env.sh;

# END NEW

# Install Spark
#wget -P "/home/ubuntu" https://dlcdn.apache.org/spark/spark-3.3.1/spark-3.3.1-bin-hadoop3-scala2.13.tgz;

echo "WGET OK ";

cd /home/ubuntu && tar xvf spark-3.3.1-bin-hadoop3-scala2.13.tgz;
echo "TAR OK ";
cd /home/ubuntu && sudo mkdir /usr/local/spark/ && sudo cp -r spark-3.3.1-bin-hadoop3-scala2.13/ /usr/local/spark/;
echo "MV OK";

cd /home/ubuntu && rm -R ExploitationDonnees && git clone https://github.com/SimonRousseaud/ExploitationDonnees.git ExploitationDonnees
echo "GIT CLONED OK "
# Deploy your application
cd /home/ubuntu && cd "ExploitationDonnees"  && mvn install
echo "MVN Install OK "

ip4=$(/sbin/ip -o -4 addr list ens33 | awk '{print $4}' | cut -d/ -f1)
echo "IP4 : "
echo "$ip4"

echo "STARTCAT"
echo "$(cat /home/ubuntu/ExploitationDonnees/config/core-site.xml)" > /home/ubuntu/hadoop-3.3.4/etc/hadoop/core-site.xml
echo "$(cat /home/ubuntu/ExploitationDonnees/config/hdfs-site.xml)" > /home/ubuntu/etc/hadoop-3.3.4/hadoop/hdfs-site.xml
echo "$(cat /home/ubuntu/ExploitationDonnees/config/mapred-site.xml)" > /home/ubuntu/etc/hadoop-3.3.4/hadoop/mapred-site.xml
echo "$(cat /home/ubuntu/ExploitationDonnees/config/yarn-site.xml)" > /home/ubuntu/hadoop-3.3.4/etc/hadoop/yarn-site.xml
echo "STARTBASH"

cd /home/ubuntu && cd hadoop-3.3.4 && bash bin/hdfs namenode -format
cd /home/ubuntu && cd hadoop-3.3.4 && bash sbin/start-dfs.sh
cd /home/ubuntu && cd hadoop-3.3.4 && bash sbin/start-yarn.sh
start-worker.sh spark://"$ip4":7077

# Execute the application
spark-submit --class org.example.main --master spark://DESKTOP-2PBH57J:7077 --driver-library-path /home/ubuntu/hadoop-3.3.4/lib/native --jars "/home/ubuntu/hadoop-3.3.4/lib/*,$SPARK_HOME/jars/*" target/Projet-javaaaaa3-1.0-SNAPSHOT.jar
